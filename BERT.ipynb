{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from preprocess import read_articles_from_file_list, read_predictions_from_file, label2index\n",
    "bc = BertClient(ip='10.2.0.111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = bc.encode(['First do it', 'then do it right', 'then do it better'])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_folder = \"datasets/train-articles\"  # check that the path to the datasets folder is correct,\n",
    "dev_folder = \"datasets/dev-articles\"  # if not adjust these variables accordingly\n",
    "test_folder = \"datasets/test-articles\"  # if not adjust these variables accordingly\n",
    "\n",
    "train_labels_file = \"datasets/train-task2-TC.labels\"\n",
    "dev_template_labels_file = \"datasets/dev-task-TC-template.out\"\n",
    "# task_TC_output_file = \"baseline-output-TC.txt\"\n",
    "\n",
    "test_template_labels_file = \"datasets/test-task-TC-template.out\"\n",
    "# test_task_TC_output_file = \"test-output-TC.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # text = text.lower()\n",
    "    # text = text.replace('\\'', '')\n",
    "    text = text.replace('‘', ' \\' ')\n",
    "    text = text.replace('’', ' \\' ')\n",
    "    text = text.replace('“', ' \\\" ')\n",
    "    text = text.replace('”', ' \\\" ')\n",
    "    text = text.replace('â', ' \\' ')\n",
    "\n",
    "    text = text.replace('\"', ' \" ')\n",
    "    text = text.replace('\\'', ' \\' ')\n",
    "\n",
    "    text = text.replace('—', ' - ')\n",
    "    text = text.replace('–', ' - ')\n",
    "    text = text.replace('…', '...')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6129 annotations from 357 articles\n"
     ]
    }
   ],
   "source": [
    "articles = read_articles_from_file_list(train_folder)\n",
    "dev_articles = read_articles_from_file_list(dev_folder)\n",
    "test_articles = read_articles_from_file_list(test_folder)\n",
    "ref_articles_id, ref_span_starts, ref_span_ends, train_gold_labels = read_predictions_from_file(train_labels_file)\n",
    "dev_article_ids, dev_span_starts, dev_span_ends, dev_labels = read_predictions_from_file(dev_template_labels_file)\n",
    "test_article_ids, test_span_starts, test_span_ends, test_labels = read_predictions_from_file(test_template_labels_file)\n",
    "print(\"Loaded %d annotations from %d articles\" % (len(ref_span_starts), len(set(ref_articles_id))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_features(articles, ref_articles_id, span_starts, span_ends):\n",
    "    # only one feature, the length of the span\n",
    "    print(type(span_starts), len(span_starts))\n",
    "    print(type(span_ends), len(span_ends))\n",
    "    data = []\n",
    "    article_spans = []\n",
    "    for i, ref_id in tqdm(enumerate(ref_articles_id)):\n",
    "        # print(articles[ref_id], span_starts[i], span_ends[i])\n",
    "        article = articles[ref_id]\n",
    "        article_span = clean_text(article[int(span_starts[i]):int(span_ends[i])])\n",
    "        data.append([article_span])\n",
    "        article_spans.append(article_span)\n",
    "        \n",
    "    return article_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6129it [00:00, 34163.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 6129\n",
      "<class 'list'> 6129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "articles = compute_features(articles, ref_articles_id, ref_span_starts, ref_span_ends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1063it [00:00, 222105.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1063\n",
      "<class 'list'> 1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_articles = compute_features(dev_articles, dev_article_ids, dev_span_starts, dev_span_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1790it [00:00, 230576.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1790\n",
      "<class 'list'> 1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_articles = compute_features(test_articles, test_article_ids, test_span_starts, test_span_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from preprocess import label2index, index2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "GET_NEW_BERT_EMB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangeshwark/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=128\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Appeal_to_Authority',\n",
      " 'Appeal_to_fear-prejudice',\n",
      " 'Bandwagon,Reductio_ad_hitlerum',\n",
      " 'Black-and-White_Fallacy',\n",
      " 'Causal_Oversimplification',\n",
      " 'Doubt',\n",
      " 'Exaggeration,Minimisation',\n",
      " 'Flag-Waving',\n",
      " 'Loaded_Language',\n",
      " 'Name_Calling,Labeling',\n",
      " 'Repetition',\n",
      " 'Slogans',\n",
      " 'Thought-terminating_Cliches',\n",
      " 'Whataboutism,Straw_Men,Red_Herring'}\n"
     ]
    }
   ],
   "source": [
    "data_path = './bert_processed_data/'\n",
    "if GET_NEW_BERT_EMB:\n",
    "    articles_emb = bc.encode(articles)\n",
    "    dev_articles_emb = bc.encode(dev_articles)\n",
    "    test_articles_emb = bc.encode(test_articles)\n",
    "    pprint(set(train_gold_labels))\n",
    "\n",
    "    labels = [label2index[x] for x in train_gold_labels]\n",
    "    labels = to_categorical(np.asarray(labels))\n",
    "\n",
    "    # save train data\n",
    "    pickle.dump(articles_emb, open(data_path + 'train_x.p', 'wb'))\n",
    "    pickle.dump(labels, open(data_path + 'train_y.p', 'wb'))\n",
    "\n",
    "    # save dev data\n",
    "    pickle.dump(dev_articles_emb, open(data_path + 'dev_x.p', 'wb'))\n",
    "    pickle.dump(dev_articles_emb, open(data_path + 'test_x.p', 'wb'))\n",
    "    \n",
    "else:\n",
    "    articles_emb = pickle.load(open(data_path + 'train_x.p', 'rb'))\n",
    "    labels = pickle.load(open(data_path + 'train_y.p', 'rb'))\n",
    "    dev_articles_emb = pickle.load(open(data_path + 'dev_x.p', 'rb'))\n",
    "    test_articles_emb = pickle.load(open(data_path + 'test_x.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(articles_emb,\n",
    "                                                  labels,\n",
    "                                                  test_size=0.20,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Bidirectional\n",
    "from keras.layers import Embedding, Concatenate\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "\n",
    "def model_MLP(emb_size, out_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=emb_size, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(out_size, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 526,222\n",
      "Trainable params: 526,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4903 samples, validate on 1226 samples\n",
      "Epoch 1/250\n",
      "4903/4903 [==============================] - 1s 216us/step - loss: 2.3650 - acc: 0.2554 - val_loss: 1.9362 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00001: saving model to models/bert_text_Adam_lr0.0001_bz256.01.hdf5\n",
      "Epoch 2/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 1.9396 - acc: 0.3781 - val_loss: 1.7142 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00002: saving model to models/bert_text_Adam_lr0.0001_bz256.02.hdf5\n",
      "Epoch 3/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 1.7619 - acc: 0.4408 - val_loss: 1.5923 - val_acc: 0.5041\n",
      "\n",
      "Epoch 00003: saving model to models/bert_text_Adam_lr0.0001_bz256.03.hdf5\n",
      "Epoch 4/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 1.6538 - acc: 0.4811 - val_loss: 1.5080 - val_acc: 0.5245\n",
      "\n",
      "Epoch 00004: saving model to models/bert_text_Adam_lr0.0001_bz256.04.hdf5\n",
      "Epoch 5/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 1.5700 - acc: 0.5125 - val_loss: 1.4432 - val_acc: 0.5408\n",
      "\n",
      "Epoch 00005: saving model to models/bert_text_Adam_lr0.0001_bz256.05.hdf5\n",
      "Epoch 6/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 1.5027 - acc: 0.5278 - val_loss: 1.3896 - val_acc: 0.5538\n",
      "\n",
      "Epoch 00006: saving model to models/bert_text_Adam_lr0.0001_bz256.06.hdf5\n",
      "Epoch 7/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 1.4410 - acc: 0.5458 - val_loss: 1.3504 - val_acc: 0.5710\n",
      "\n",
      "Epoch 00007: saving model to models/bert_text_Adam_lr0.0001_bz256.07.hdf5\n",
      "Epoch 8/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 1.3955 - acc: 0.5574 - val_loss: 1.3147 - val_acc: 0.5816\n",
      "\n",
      "Epoch 00008: saving model to models/bert_text_Adam_lr0.0001_bz256.08.hdf5\n",
      "Epoch 9/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 1.3547 - acc: 0.5745 - val_loss: 1.2839 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00009: saving model to models/bert_text_Adam_lr0.0001_bz256.09.hdf5\n",
      "Epoch 10/250\n",
      "4903/4903 [==============================] - 0s 34us/step - loss: 1.3308 - acc: 0.5884 - val_loss: 1.2605 - val_acc: 0.6044\n",
      "\n",
      "Epoch 00010: saving model to models/bert_text_Adam_lr0.0001_bz256.10.hdf5\n",
      "Epoch 11/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 1.2794 - acc: 0.5911 - val_loss: 1.2356 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00011: saving model to models/bert_text_Adam_lr0.0001_bz256.11.hdf5\n",
      "Epoch 12/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 1.2235 - acc: 0.6104 - val_loss: 1.2152 - val_acc: 0.6199\n",
      "\n",
      "Epoch 00012: saving model to models/bert_text_Adam_lr0.0001_bz256.12.hdf5\n",
      "Epoch 13/250\n",
      "4903/4903 [==============================] - 0s 34us/step - loss: 1.2244 - acc: 0.6098 - val_loss: 1.1999 - val_acc: 0.6134\n",
      "\n",
      "Epoch 00013: saving model to models/bert_text_Adam_lr0.0001_bz256.13.hdf5\n",
      "Epoch 14/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 1.1936 - acc: 0.6151 - val_loss: 1.1887 - val_acc: 0.6232\n",
      "\n",
      "Epoch 00014: saving model to models/bert_text_Adam_lr0.0001_bz256.14.hdf5\n",
      "Epoch 15/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 1.1731 - acc: 0.6231 - val_loss: 1.1747 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00015: saving model to models/bert_text_Adam_lr0.0001_bz256.15.hdf5\n",
      "Epoch 16/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 1.1413 - acc: 0.6394 - val_loss: 1.1684 - val_acc: 0.6289\n",
      "\n",
      "Epoch 00016: saving model to models/bert_text_Adam_lr0.0001_bz256.16.hdf5\n",
      "Epoch 17/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 1.1093 - acc: 0.6494 - val_loss: 1.1539 - val_acc: 0.6387\n",
      "\n",
      "Epoch 00017: saving model to models/bert_text_Adam_lr0.0001_bz256.17.hdf5\n",
      "Epoch 18/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 1.0953 - acc: 0.6561 - val_loss: 1.1494 - val_acc: 0.6370\n",
      "\n",
      "Epoch 00018: saving model to models/bert_text_Adam_lr0.0001_bz256.18.hdf5\n",
      "Epoch 19/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 1.0712 - acc: 0.6531 - val_loss: 1.1335 - val_acc: 0.6411\n",
      "\n",
      "Epoch 00019: saving model to models/bert_text_Adam_lr0.0001_bz256.19.hdf5\n",
      "Epoch 20/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 1.0611 - acc: 0.6622 - val_loss: 1.1343 - val_acc: 0.6411\n",
      "\n",
      "Epoch 00020: saving model to models/bert_text_Adam_lr0.0001_bz256.20.hdf5\n",
      "Epoch 21/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 1.0421 - acc: 0.6673 - val_loss: 1.1222 - val_acc: 0.6395\n",
      "\n",
      "Epoch 00021: saving model to models/bert_text_Adam_lr0.0001_bz256.21.hdf5\n",
      "Epoch 22/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 1.0329 - acc: 0.6780 - val_loss: 1.1170 - val_acc: 0.6444\n",
      "\n",
      "Epoch 00022: saving model to models/bert_text_Adam_lr0.0001_bz256.22.hdf5\n",
      "Epoch 23/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 1.0008 - acc: 0.6841 - val_loss: 1.1157 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00023: saving model to models/bert_text_Adam_lr0.0001_bz256.23.hdf5\n",
      "Epoch 24/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 1.0020 - acc: 0.6804 - val_loss: 1.1110 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00024: saving model to models/bert_text_Adam_lr0.0001_bz256.24.hdf5\n",
      "Epoch 25/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.9802 - acc: 0.6875 - val_loss: 1.1034 - val_acc: 0.6427\n",
      "\n",
      "Epoch 00025: saving model to models/bert_text_Adam_lr0.0001_bz256.25.hdf5\n",
      "Epoch 26/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.9836 - acc: 0.6879 - val_loss: 1.0976 - val_acc: 0.6444\n",
      "\n",
      "Epoch 00026: saving model to models/bert_text_Adam_lr0.0001_bz256.26.hdf5\n",
      "Epoch 27/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.9504 - acc: 0.6977 - val_loss: 1.0945 - val_acc: 0.6452\n",
      "\n",
      "Epoch 00027: saving model to models/bert_text_Adam_lr0.0001_bz256.27.hdf5\n",
      "Epoch 28/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.9380 - acc: 0.7020 - val_loss: 1.0895 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00028: saving model to models/bert_text_Adam_lr0.0001_bz256.28.hdf5\n",
      "Epoch 29/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.9302 - acc: 0.7057 - val_loss: 1.0876 - val_acc: 0.6501\n",
      "\n",
      "Epoch 00029: saving model to models/bert_text_Adam_lr0.0001_bz256.29.hdf5\n",
      "Epoch 30/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.9192 - acc: 0.7043 - val_loss: 1.0893 - val_acc: 0.6533\n",
      "\n",
      "Epoch 00030: saving model to models/bert_text_Adam_lr0.0001_bz256.30.hdf5\n",
      "Epoch 31/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.8933 - acc: 0.7212 - val_loss: 1.0826 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00031: saving model to models/bert_text_Adam_lr0.0001_bz256.31.hdf5\n",
      "Epoch 32/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.8927 - acc: 0.7147 - val_loss: 1.0800 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00032: saving model to models/bert_text_Adam_lr0.0001_bz256.32.hdf5\n",
      "Epoch 33/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.8725 - acc: 0.7198 - val_loss: 1.0781 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00033: saving model to models/bert_text_Adam_lr0.0001_bz256.33.hdf5\n",
      "Epoch 34/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.8630 - acc: 0.7249 - val_loss: 1.0762 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00034: saving model to models/bert_text_Adam_lr0.0001_bz256.34.hdf5\n",
      "Epoch 35/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.8535 - acc: 0.7312 - val_loss: 1.0761 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00035: saving model to models/bert_text_Adam_lr0.0001_bz256.35.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.8512 - acc: 0.7293 - val_loss: 1.0754 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00036: saving model to models/bert_text_Adam_lr0.0001_bz256.36.hdf5\n",
      "Epoch 37/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.8319 - acc: 0.7361 - val_loss: 1.0720 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00037: saving model to models/bert_text_Adam_lr0.0001_bz256.37.hdf5\n",
      "Epoch 38/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.8241 - acc: 0.7404 - val_loss: 1.0734 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00038: saving model to models/bert_text_Adam_lr0.0001_bz256.38.hdf5\n",
      "Epoch 39/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.8159 - acc: 0.7373 - val_loss: 1.0717 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00039: saving model to models/bert_text_Adam_lr0.0001_bz256.39.hdf5\n",
      "Epoch 40/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.8087 - acc: 0.7485 - val_loss: 1.0707 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00040: saving model to models/bert_text_Adam_lr0.0001_bz256.40.hdf5\n",
      "Epoch 41/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.7945 - acc: 0.7465 - val_loss: 1.0662 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00041: saving model to models/bert_text_Adam_lr0.0001_bz256.41.hdf5\n",
      "Epoch 42/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.7883 - acc: 0.7493 - val_loss: 1.0650 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00042: saving model to models/bert_text_Adam_lr0.0001_bz256.42.hdf5\n",
      "Epoch 43/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.7833 - acc: 0.7583 - val_loss: 1.0661 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00043: saving model to models/bert_text_Adam_lr0.0001_bz256.43.hdf5\n",
      "Epoch 44/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.7741 - acc: 0.7530 - val_loss: 1.0692 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00044: saving model to models/bert_text_Adam_lr0.0001_bz256.44.hdf5\n",
      "Epoch 45/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.7646 - acc: 0.7593 - val_loss: 1.0625 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00045: saving model to models/bert_text_Adam_lr0.0001_bz256.45.hdf5\n",
      "Epoch 46/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.7468 - acc: 0.7671 - val_loss: 1.0608 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00046: saving model to models/bert_text_Adam_lr0.0001_bz256.46.hdf5\n",
      "Epoch 47/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.7424 - acc: 0.7710 - val_loss: 1.0616 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00047: saving model to models/bert_text_Adam_lr0.0001_bz256.47.hdf5\n",
      "Epoch 48/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.7408 - acc: 0.7720 - val_loss: 1.0630 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00048: saving model to models/bert_text_Adam_lr0.0001_bz256.48.hdf5\n",
      "Epoch 49/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.7282 - acc: 0.7759 - val_loss: 1.0641 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00049: saving model to models/bert_text_Adam_lr0.0001_bz256.49.hdf5\n",
      "Epoch 50/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.7122 - acc: 0.7822 - val_loss: 1.0604 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00050: saving model to models/bert_text_Adam_lr0.0001_bz256.50.hdf5\n",
      "Epoch 51/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.7056 - acc: 0.7793 - val_loss: 1.0606 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00051: saving model to models/bert_text_Adam_lr0.0001_bz256.51.hdf5\n",
      "Epoch 52/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.6962 - acc: 0.7797 - val_loss: 1.0591 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00052: saving model to models/bert_text_Adam_lr0.0001_bz256.52.hdf5\n",
      "Epoch 53/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.7100 - acc: 0.7781 - val_loss: 1.0594 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00053: saving model to models/bert_text_Adam_lr0.0001_bz256.53.hdf5\n",
      "Epoch 54/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.6877 - acc: 0.7854 - val_loss: 1.0619 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00054: saving model to models/bert_text_Adam_lr0.0001_bz256.54.hdf5\n",
      "Epoch 55/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.6928 - acc: 0.7816 - val_loss: 1.0602 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00055: saving model to models/bert_text_Adam_lr0.0001_bz256.55.hdf5\n",
      "Epoch 56/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.6743 - acc: 0.7891 - val_loss: 1.0585 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00056: saving model to models/bert_text_Adam_lr0.0001_bz256.56.hdf5\n",
      "Epoch 57/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.6723 - acc: 0.7922 - val_loss: 1.0580 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00057: saving model to models/bert_text_Adam_lr0.0001_bz256.57.hdf5\n",
      "Epoch 58/250\n",
      "4903/4903 [==============================] - 0s 42us/step - loss: 0.6718 - acc: 0.7848 - val_loss: 1.0613 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00058: saving model to models/bert_text_Adam_lr0.0001_bz256.58.hdf5\n",
      "Epoch 59/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.6579 - acc: 0.7985 - val_loss: 1.0638 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00059: saving model to models/bert_text_Adam_lr0.0001_bz256.59.hdf5\n",
      "Epoch 60/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.6381 - acc: 0.8075 - val_loss: 1.0589 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00060: saving model to models/bert_text_Adam_lr0.0001_bz256.60.hdf5\n",
      "Epoch 61/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.6434 - acc: 0.7997 - val_loss: 1.0569 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00061: saving model to models/bert_text_Adam_lr0.0001_bz256.61.hdf5\n",
      "Epoch 62/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.6421 - acc: 0.7975 - val_loss: 1.0584 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00062: saving model to models/bert_text_Adam_lr0.0001_bz256.62.hdf5\n",
      "Epoch 63/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.6275 - acc: 0.8105 - val_loss: 1.0595 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00063: saving model to models/bert_text_Adam_lr0.0001_bz256.63.hdf5\n",
      "Epoch 64/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.6162 - acc: 0.8146 - val_loss: 1.0624 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00064: saving model to models/bert_text_Adam_lr0.0001_bz256.64.hdf5\n",
      "Epoch 65/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.6086 - acc: 0.8093 - val_loss: 1.0647 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00065: saving model to models/bert_text_Adam_lr0.0001_bz256.65.hdf5\n",
      "Epoch 66/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.6108 - acc: 0.8122 - val_loss: 1.0611 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00066: saving model to models/bert_text_Adam_lr0.0001_bz256.66.hdf5\n",
      "Epoch 67/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.6044 - acc: 0.8162 - val_loss: 1.0608 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00067: saving model to models/bert_text_Adam_lr0.0001_bz256.67.hdf5\n",
      "Epoch 68/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.5973 - acc: 0.8181 - val_loss: 1.0651 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00068: saving model to models/bert_text_Adam_lr0.0001_bz256.68.hdf5\n",
      "Epoch 69/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.5934 - acc: 0.8299 - val_loss: 1.0648 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00069: saving model to models/bert_text_Adam_lr0.0001_bz256.69.hdf5\n",
      "Epoch 70/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.5877 - acc: 0.8136 - val_loss: 1.0617 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00070: saving model to models/bert_text_Adam_lr0.0001_bz256.70.hdf5\n",
      "Epoch 71/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.5796 - acc: 0.8197 - val_loss: 1.0677 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00071: saving model to models/bert_text_Adam_lr0.0001_bz256.71.hdf5\n",
      "Epoch 72/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.5743 - acc: 0.8187 - val_loss: 1.0621 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00072: saving model to models/bert_text_Adam_lr0.0001_bz256.72.hdf5\n",
      "Epoch 73/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.5717 - acc: 0.8281 - val_loss: 1.0643 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00073: saving model to models/bert_text_Adam_lr0.0001_bz256.73.hdf5\n",
      "Epoch 74/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.5704 - acc: 0.8211 - val_loss: 1.0647 - val_acc: 0.6591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: saving model to models/bert_text_Adam_lr0.0001_bz256.74.hdf5\n",
      "Epoch 75/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.5598 - acc: 0.8311 - val_loss: 1.0651 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00075: saving model to models/bert_text_Adam_lr0.0001_bz256.75.hdf5\n",
      "Epoch 76/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.5603 - acc: 0.8354 - val_loss: 1.0641 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00076: saving model to models/bert_text_Adam_lr0.0001_bz256.76.hdf5\n",
      "Epoch 77/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.5425 - acc: 0.8313 - val_loss: 1.0645 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00077: saving model to models/bert_text_Adam_lr0.0001_bz256.77.hdf5\n",
      "Epoch 78/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.5445 - acc: 0.8436 - val_loss: 1.0678 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00078: saving model to models/bert_text_Adam_lr0.0001_bz256.78.hdf5\n",
      "Epoch 79/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.5413 - acc: 0.8377 - val_loss: 1.0649 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00079: saving model to models/bert_text_Adam_lr0.0001_bz256.79.hdf5\n",
      "Epoch 80/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.5489 - acc: 0.8315 - val_loss: 1.0641 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00080: saving model to models/bert_text_Adam_lr0.0001_bz256.80.hdf5\n",
      "Epoch 81/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.5366 - acc: 0.8370 - val_loss: 1.0655 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00081: saving model to models/bert_text_Adam_lr0.0001_bz256.81.hdf5\n",
      "Epoch 82/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.5243 - acc: 0.8417 - val_loss: 1.0640 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00082: saving model to models/bert_text_Adam_lr0.0001_bz256.82.hdf5\n",
      "Epoch 83/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 0.5154 - acc: 0.8474 - val_loss: 1.0686 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00083: saving model to models/bert_text_Adam_lr0.0001_bz256.83.hdf5\n",
      "Epoch 84/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.5251 - acc: 0.8379 - val_loss: 1.0644 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00084: saving model to models/bert_text_Adam_lr0.0001_bz256.84.hdf5\n",
      "Epoch 85/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.5129 - acc: 0.8405 - val_loss: 1.0730 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00085: saving model to models/bert_text_Adam_lr0.0001_bz256.85.hdf5\n",
      "Epoch 86/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.5029 - acc: 0.8466 - val_loss: 1.0751 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00086: saving model to models/bert_text_Adam_lr0.0001_bz256.86.hdf5\n",
      "Epoch 87/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.5067 - acc: 0.8464 - val_loss: 1.0704 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00087: saving model to models/bert_text_Adam_lr0.0001_bz256.87.hdf5\n",
      "Epoch 88/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.4976 - acc: 0.8495 - val_loss: 1.0697 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00088: saving model to models/bert_text_Adam_lr0.0001_bz256.88.hdf5\n",
      "Epoch 89/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.4953 - acc: 0.8474 - val_loss: 1.0743 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00089: saving model to models/bert_text_Adam_lr0.0001_bz256.89.hdf5\n",
      "Epoch 90/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.4806 - acc: 0.8593 - val_loss: 1.0785 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00090: saving model to models/bert_text_Adam_lr0.0001_bz256.90.hdf5\n",
      "Epoch 91/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.4772 - acc: 0.8595 - val_loss: 1.0791 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00091: saving model to models/bert_text_Adam_lr0.0001_bz256.91.hdf5\n",
      "Epoch 92/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.4705 - acc: 0.8605 - val_loss: 1.0813 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00092: saving model to models/bert_text_Adam_lr0.0001_bz256.92.hdf5\n",
      "Epoch 93/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.4769 - acc: 0.8619 - val_loss: 1.0777 - val_acc: 0.6688\n",
      "\n",
      "Epoch 00093: saving model to models/bert_text_Adam_lr0.0001_bz256.93.hdf5\n",
      "Epoch 94/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.4637 - acc: 0.8587 - val_loss: 1.0770 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00094: saving model to models/bert_text_Adam_lr0.0001_bz256.94.hdf5\n",
      "Epoch 95/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.4608 - acc: 0.8603 - val_loss: 1.0835 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00095: saving model to models/bert_text_Adam_lr0.0001_bz256.95.hdf5\n",
      "Epoch 96/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.4670 - acc: 0.8609 - val_loss: 1.0866 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00096: saving model to models/bert_text_Adam_lr0.0001_bz256.96.hdf5\n",
      "Epoch 97/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.4607 - acc: 0.8648 - val_loss: 1.0819 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00097: saving model to models/bert_text_Adam_lr0.0001_bz256.97.hdf5\n",
      "Epoch 98/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.4558 - acc: 0.8644 - val_loss: 1.0882 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00098: saving model to models/bert_text_Adam_lr0.0001_bz256.98.hdf5\n",
      "Epoch 99/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.4512 - acc: 0.8705 - val_loss: 1.0821 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00099: saving model to models/bert_text_Adam_lr0.0001_bz256.99.hdf5\n",
      "Epoch 100/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.4399 - acc: 0.8719 - val_loss: 1.0847 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00100: saving model to models/bert_text_Adam_lr0.0001_bz256.100.hdf5\n",
      "Epoch 101/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.4436 - acc: 0.8668 - val_loss: 1.0914 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00101: saving model to models/bert_text_Adam_lr0.0001_bz256.101.hdf5\n",
      "Epoch 102/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.4370 - acc: 0.8723 - val_loss: 1.0911 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00102: saving model to models/bert_text_Adam_lr0.0001_bz256.102.hdf5\n",
      "Epoch 103/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.4331 - acc: 0.8746 - val_loss: 1.0934 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00103: saving model to models/bert_text_Adam_lr0.0001_bz256.103.hdf5\n",
      "Epoch 104/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.4312 - acc: 0.8709 - val_loss: 1.0929 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00104: saving model to models/bert_text_Adam_lr0.0001_bz256.104.hdf5\n",
      "Epoch 105/250\n",
      "4903/4903 [==============================] - 0s 20us/step - loss: 0.4237 - acc: 0.8772 - val_loss: 1.0944 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00105: saving model to models/bert_text_Adam_lr0.0001_bz256.105.hdf5\n",
      "Epoch 106/250\n",
      "4903/4903 [==============================] - 0s 22us/step - loss: 0.4296 - acc: 0.8717 - val_loss: 1.0939 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00106: saving model to models/bert_text_Adam_lr0.0001_bz256.106.hdf5\n",
      "Epoch 107/250\n",
      "4903/4903 [==============================] - 0s 21us/step - loss: 0.4176 - acc: 0.8788 - val_loss: 1.0970 - val_acc: 0.6697\n",
      "\n",
      "Epoch 00107: saving model to models/bert_text_Adam_lr0.0001_bz256.107.hdf5\n",
      "Epoch 108/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.4156 - acc: 0.8772 - val_loss: 1.1021 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00108: saving model to models/bert_text_Adam_lr0.0001_bz256.108.hdf5\n",
      "Epoch 109/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 0.4114 - acc: 0.8776 - val_loss: 1.0982 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00109: saving model to models/bert_text_Adam_lr0.0001_bz256.109.hdf5\n",
      "Epoch 110/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.4141 - acc: 0.8758 - val_loss: 1.0969 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00110: saving model to models/bert_text_Adam_lr0.0001_bz256.110.hdf5\n",
      "Epoch 111/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.4144 - acc: 0.8782 - val_loss: 1.0946 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00111: saving model to models/bert_text_Adam_lr0.0001_bz256.111.hdf5\n",
      "Epoch 112/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.4061 - acc: 0.8856 - val_loss: 1.1003 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00112: saving model to models/bert_text_Adam_lr0.0001_bz256.112.hdf5\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3990 - acc: 0.8886 - val_loss: 1.1031 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00113: saving model to models/bert_text_Adam_lr0.0001_bz256.113.hdf5\n",
      "Epoch 114/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3921 - acc: 0.8888 - val_loss: 1.1059 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00114: saving model to models/bert_text_Adam_lr0.0001_bz256.114.hdf5\n",
      "Epoch 115/250\n",
      "4903/4903 [==============================] - 0s 36us/step - loss: 0.3969 - acc: 0.8866 - val_loss: 1.1056 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00115: saving model to models/bert_text_Adam_lr0.0001_bz256.115.hdf5\n",
      "Epoch 116/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3893 - acc: 0.8909 - val_loss: 1.1060 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00116: saving model to models/bert_text_Adam_lr0.0001_bz256.116.hdf5\n",
      "Epoch 117/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.3957 - acc: 0.8850 - val_loss: 1.1107 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00117: saving model to models/bert_text_Adam_lr0.0001_bz256.117.hdf5\n",
      "Epoch 118/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3815 - acc: 0.8882 - val_loss: 1.1102 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00118: saving model to models/bert_text_Adam_lr0.0001_bz256.118.hdf5\n",
      "Epoch 119/250\n",
      "4903/4903 [==============================] - 0s 21us/step - loss: 0.3826 - acc: 0.8899 - val_loss: 1.1114 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00119: saving model to models/bert_text_Adam_lr0.0001_bz256.119.hdf5\n",
      "Epoch 120/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.3841 - acc: 0.8901 - val_loss: 1.1120 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00120: saving model to models/bert_text_Adam_lr0.0001_bz256.120.hdf5\n",
      "Epoch 121/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.3792 - acc: 0.8909 - val_loss: 1.1174 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00121: saving model to models/bert_text_Adam_lr0.0001_bz256.121.hdf5\n",
      "Epoch 122/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.3712 - acc: 0.8960 - val_loss: 1.1192 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00122: saving model to models/bert_text_Adam_lr0.0001_bz256.122.hdf5\n",
      "Epoch 123/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3661 - acc: 0.8966 - val_loss: 1.1227 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00123: saving model to models/bert_text_Adam_lr0.0001_bz256.123.hdf5\n",
      "Epoch 124/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.3669 - acc: 0.8984 - val_loss: 1.1208 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00124: saving model to models/bert_text_Adam_lr0.0001_bz256.124.hdf5\n",
      "Epoch 125/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3613 - acc: 0.8954 - val_loss: 1.1255 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00125: saving model to models/bert_text_Adam_lr0.0001_bz256.125.hdf5\n",
      "Epoch 126/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.3536 - acc: 0.8988 - val_loss: 1.1219 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00126: saving model to models/bert_text_Adam_lr0.0001_bz256.126.hdf5\n",
      "Epoch 127/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.3560 - acc: 0.8976 - val_loss: 1.1197 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00127: saving model to models/bert_text_Adam_lr0.0001_bz256.127.hdf5\n",
      "Epoch 128/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.3637 - acc: 0.8946 - val_loss: 1.1238 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00128: saving model to models/bert_text_Adam_lr0.0001_bz256.128.hdf5\n",
      "Epoch 129/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.3540 - acc: 0.9019 - val_loss: 1.1252 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00129: saving model to models/bert_text_Adam_lr0.0001_bz256.129.hdf5\n",
      "Epoch 130/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.3492 - acc: 0.9005 - val_loss: 1.1297 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00130: saving model to models/bert_text_Adam_lr0.0001_bz256.130.hdf5\n",
      "Epoch 131/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3485 - acc: 0.9015 - val_loss: 1.1328 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00131: saving model to models/bert_text_Adam_lr0.0001_bz256.131.hdf5\n",
      "Epoch 132/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.3439 - acc: 0.9025 - val_loss: 1.1318 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00132: saving model to models/bert_text_Adam_lr0.0001_bz256.132.hdf5\n",
      "Epoch 133/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.3483 - acc: 0.9025 - val_loss: 1.1349 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00133: saving model to models/bert_text_Adam_lr0.0001_bz256.133.hdf5\n",
      "Epoch 134/250\n",
      "4903/4903 [==============================] - 0s 39us/step - loss: 0.3437 - acc: 0.9007 - val_loss: 1.1368 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00134: saving model to models/bert_text_Adam_lr0.0001_bz256.134.hdf5\n",
      "Epoch 135/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.3326 - acc: 0.9123 - val_loss: 1.1450 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00135: saving model to models/bert_text_Adam_lr0.0001_bz256.135.hdf5\n",
      "Epoch 136/250\n",
      "4903/4903 [==============================] - 0s 34us/step - loss: 0.3415 - acc: 0.9045 - val_loss: 1.1330 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00136: saving model to models/bert_text_Adam_lr0.0001_bz256.136.hdf5\n",
      "Epoch 137/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.3313 - acc: 0.9105 - val_loss: 1.1348 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00137: saving model to models/bert_text_Adam_lr0.0001_bz256.137.hdf5\n",
      "Epoch 138/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3324 - acc: 0.9029 - val_loss: 1.1419 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00138: saving model to models/bert_text_Adam_lr0.0001_bz256.138.hdf5\n",
      "Epoch 139/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3260 - acc: 0.9101 - val_loss: 1.1387 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00139: saving model to models/bert_text_Adam_lr0.0001_bz256.139.hdf5\n",
      "Epoch 140/250\n",
      "4903/4903 [==============================] - 0s 21us/step - loss: 0.3237 - acc: 0.9080 - val_loss: 1.1455 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00140: saving model to models/bert_text_Adam_lr0.0001_bz256.140.hdf5\n",
      "Epoch 141/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3196 - acc: 0.9072 - val_loss: 1.1425 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00141: saving model to models/bert_text_Adam_lr0.0001_bz256.141.hdf5\n",
      "Epoch 142/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3220 - acc: 0.9048 - val_loss: 1.1505 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00142: saving model to models/bert_text_Adam_lr0.0001_bz256.142.hdf5\n",
      "Epoch 143/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3175 - acc: 0.9133 - val_loss: 1.1477 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00143: saving model to models/bert_text_Adam_lr0.0001_bz256.143.hdf5\n",
      "Epoch 144/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.3082 - acc: 0.9141 - val_loss: 1.1486 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00144: saving model to models/bert_text_Adam_lr0.0001_bz256.144.hdf5\n",
      "Epoch 145/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3125 - acc: 0.9099 - val_loss: 1.1562 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00145: saving model to models/bert_text_Adam_lr0.0001_bz256.145.hdf5\n",
      "Epoch 146/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3123 - acc: 0.9131 - val_loss: 1.1501 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00146: saving model to models/bert_text_Adam_lr0.0001_bz256.146.hdf5\n",
      "Epoch 147/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3098 - acc: 0.9164 - val_loss: 1.1533 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00147: saving model to models/bert_text_Adam_lr0.0001_bz256.147.hdf5\n",
      "Epoch 148/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.3051 - acc: 0.9150 - val_loss: 1.1579 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00148: saving model to models/bert_text_Adam_lr0.0001_bz256.148.hdf5\n",
      "Epoch 149/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.2987 - acc: 0.9168 - val_loss: 1.1574 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00149: saving model to models/bert_text_Adam_lr0.0001_bz256.149.hdf5\n",
      "Epoch 150/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.3087 - acc: 0.9178 - val_loss: 1.1595 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00150: saving model to models/bert_text_Adam_lr0.0001_bz256.150.hdf5\n",
      "Epoch 151/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.3003 - acc: 0.9164 - val_loss: 1.1687 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00151: saving model to models/bert_text_Adam_lr0.0001_bz256.151.hdf5\n",
      "Epoch 152/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.3002 - acc: 0.9135 - val_loss: 1.1623 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00152: saving model to models/bert_text_Adam_lr0.0001_bz256.152.hdf5\n",
      "Epoch 153/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.3064 - acc: 0.9086 - val_loss: 1.1582 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00153: saving model to models/bert_text_Adam_lr0.0001_bz256.153.hdf5\n",
      "Epoch 154/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.2887 - acc: 0.9237 - val_loss: 1.1694 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00154: saving model to models/bert_text_Adam_lr0.0001_bz256.154.hdf5\n",
      "Epoch 155/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.2866 - acc: 0.9168 - val_loss: 1.1670 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00155: saving model to models/bert_text_Adam_lr0.0001_bz256.155.hdf5\n",
      "Epoch 156/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.2902 - acc: 0.9170 - val_loss: 1.1671 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00156: saving model to models/bert_text_Adam_lr0.0001_bz256.156.hdf5\n",
      "Epoch 157/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2914 - acc: 0.9158 - val_loss: 1.1706 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00157: saving model to models/bert_text_Adam_lr0.0001_bz256.157.hdf5\n",
      "Epoch 158/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2810 - acc: 0.9231 - val_loss: 1.1733 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00158: saving model to models/bert_text_Adam_lr0.0001_bz256.158.hdf5\n",
      "Epoch 159/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2895 - acc: 0.9239 - val_loss: 1.1748 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00159: saving model to models/bert_text_Adam_lr0.0001_bz256.159.hdf5\n",
      "Epoch 160/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.2785 - acc: 0.9266 - val_loss: 1.1737 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00160: saving model to models/bert_text_Adam_lr0.0001_bz256.160.hdf5\n",
      "Epoch 161/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2792 - acc: 0.9272 - val_loss: 1.1725 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00161: saving model to models/bert_text_Adam_lr0.0001_bz256.161.hdf5\n",
      "Epoch 162/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2773 - acc: 0.9233 - val_loss: 1.1749 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00162: saving model to models/bert_text_Adam_lr0.0001_bz256.162.hdf5\n",
      "Epoch 163/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2738 - acc: 0.9280 - val_loss: 1.1838 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00163: saving model to models/bert_text_Adam_lr0.0001_bz256.163.hdf5\n",
      "Epoch 164/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2738 - acc: 0.9227 - val_loss: 1.1789 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00164: saving model to models/bert_text_Adam_lr0.0001_bz256.164.hdf5\n",
      "Epoch 165/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.2698 - acc: 0.9268 - val_loss: 1.1855 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00165: saving model to models/bert_text_Adam_lr0.0001_bz256.165.hdf5\n",
      "Epoch 166/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2737 - acc: 0.9251 - val_loss: 1.1780 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00166: saving model to models/bert_text_Adam_lr0.0001_bz256.166.hdf5\n",
      "Epoch 167/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2670 - acc: 0.9276 - val_loss: 1.1818 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00167: saving model to models/bert_text_Adam_lr0.0001_bz256.167.hdf5\n",
      "Epoch 168/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.2674 - acc: 0.9286 - val_loss: 1.1802 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00168: saving model to models/bert_text_Adam_lr0.0001_bz256.168.hdf5\n",
      "Epoch 169/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2657 - acc: 0.9282 - val_loss: 1.1892 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00169: saving model to models/bert_text_Adam_lr0.0001_bz256.169.hdf5\n",
      "Epoch 170/250\n",
      "4903/4903 [==============================] - 0s 21us/step - loss: 0.2658 - acc: 0.9282 - val_loss: 1.1900 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00170: saving model to models/bert_text_Adam_lr0.0001_bz256.170.hdf5\n",
      "Epoch 171/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2583 - acc: 0.9323 - val_loss: 1.1913 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00171: saving model to models/bert_text_Adam_lr0.0001_bz256.171.hdf5\n",
      "Epoch 172/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2525 - acc: 0.9358 - val_loss: 1.1976 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00172: saving model to models/bert_text_Adam_lr0.0001_bz256.172.hdf5\n",
      "Epoch 173/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2540 - acc: 0.9309 - val_loss: 1.1912 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00173: saving model to models/bert_text_Adam_lr0.0001_bz256.173.hdf5\n",
      "Epoch 174/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.2568 - acc: 0.9313 - val_loss: 1.1986 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00174: saving model to models/bert_text_Adam_lr0.0001_bz256.174.hdf5\n",
      "Epoch 175/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.2507 - acc: 0.9325 - val_loss: 1.2008 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00175: saving model to models/bert_text_Adam_lr0.0001_bz256.175.hdf5\n",
      "Epoch 176/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.2472 - acc: 0.9372 - val_loss: 1.2017 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00176: saving model to models/bert_text_Adam_lr0.0001_bz256.176.hdf5\n",
      "Epoch 177/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2505 - acc: 0.9343 - val_loss: 1.2024 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00177: saving model to models/bert_text_Adam_lr0.0001_bz256.177.hdf5\n",
      "Epoch 178/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.2488 - acc: 0.9345 - val_loss: 1.2065 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00178: saving model to models/bert_text_Adam_lr0.0001_bz256.178.hdf5\n",
      "Epoch 179/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2449 - acc: 0.9305 - val_loss: 1.2135 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00179: saving model to models/bert_text_Adam_lr0.0001_bz256.179.hdf5\n",
      "Epoch 180/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.2517 - acc: 0.9337 - val_loss: 1.2091 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00180: saving model to models/bert_text_Adam_lr0.0001_bz256.180.hdf5\n",
      "Epoch 181/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2417 - acc: 0.9378 - val_loss: 1.2170 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00181: saving model to models/bert_text_Adam_lr0.0001_bz256.181.hdf5\n",
      "Epoch 182/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2444 - acc: 0.9325 - val_loss: 1.2147 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00182: saving model to models/bert_text_Adam_lr0.0001_bz256.182.hdf5\n",
      "Epoch 183/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.2366 - acc: 0.9366 - val_loss: 1.2178 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00183: saving model to models/bert_text_Adam_lr0.0001_bz256.183.hdf5\n",
      "Epoch 184/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.2399 - acc: 0.9355 - val_loss: 1.2075 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00184: saving model to models/bert_text_Adam_lr0.0001_bz256.184.hdf5\n",
      "Epoch 185/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.2415 - acc: 0.9355 - val_loss: 1.2203 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00185: saving model to models/bert_text_Adam_lr0.0001_bz256.185.hdf5\n",
      "Epoch 186/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2327 - acc: 0.9411 - val_loss: 1.2212 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00186: saving model to models/bert_text_Adam_lr0.0001_bz256.186.hdf5\n",
      "Epoch 187/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2411 - acc: 0.9339 - val_loss: 1.2231 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00187: saving model to models/bert_text_Adam_lr0.0001_bz256.187.hdf5\n",
      "Epoch 188/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2302 - acc: 0.9366 - val_loss: 1.2265 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00188: saving model to models/bert_text_Adam_lr0.0001_bz256.188.hdf5\n",
      "Epoch 189/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4903/4903 [==============================] - 0s 34us/step - loss: 0.2362 - acc: 0.9384 - val_loss: 1.2307 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00189: saving model to models/bert_text_Adam_lr0.0001_bz256.189.hdf5\n",
      "Epoch 190/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.2349 - acc: 0.9353 - val_loss: 1.2261 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00190: saving model to models/bert_text_Adam_lr0.0001_bz256.190.hdf5\n",
      "Epoch 191/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.2294 - acc: 0.9380 - val_loss: 1.2272 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00191: saving model to models/bert_text_Adam_lr0.0001_bz256.191.hdf5\n",
      "Epoch 192/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.2313 - acc: 0.9366 - val_loss: 1.2220 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00192: saving model to models/bert_text_Adam_lr0.0001_bz256.192.hdf5\n",
      "Epoch 193/250\n",
      "4903/4903 [==============================] - 0s 35us/step - loss: 0.2264 - acc: 0.9406 - val_loss: 1.2423 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00193: saving model to models/bert_text_Adam_lr0.0001_bz256.193.hdf5\n",
      "Epoch 194/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2221 - acc: 0.9400 - val_loss: 1.2289 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00194: saving model to models/bert_text_Adam_lr0.0001_bz256.194.hdf5\n",
      "Epoch 195/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.2232 - acc: 0.9435 - val_loss: 1.2319 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00195: saving model to models/bert_text_Adam_lr0.0001_bz256.195.hdf5\n",
      "Epoch 196/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2212 - acc: 0.9398 - val_loss: 1.2410 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00196: saving model to models/bert_text_Adam_lr0.0001_bz256.196.hdf5\n",
      "Epoch 197/250\n",
      "4903/4903 [==============================] - 0s 23us/step - loss: 0.2172 - acc: 0.9478 - val_loss: 1.2526 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00197: saving model to models/bert_text_Adam_lr0.0001_bz256.197.hdf5\n",
      "Epoch 198/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2185 - acc: 0.9431 - val_loss: 1.2421 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00198: saving model to models/bert_text_Adam_lr0.0001_bz256.198.hdf5\n",
      "Epoch 199/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2205 - acc: 0.9374 - val_loss: 1.2412 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00199: saving model to models/bert_text_Adam_lr0.0001_bz256.199.hdf5\n",
      "Epoch 200/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.2136 - acc: 0.9423 - val_loss: 1.2493 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00200: saving model to models/bert_text_Adam_lr0.0001_bz256.200.hdf5\n",
      "Epoch 201/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.2111 - acc: 0.9457 - val_loss: 1.2524 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00201: saving model to models/bert_text_Adam_lr0.0001_bz256.201.hdf5\n",
      "Epoch 202/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.2221 - acc: 0.9374 - val_loss: 1.2430 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00202: saving model to models/bert_text_Adam_lr0.0001_bz256.202.hdf5\n",
      "Epoch 203/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.2160 - acc: 0.9423 - val_loss: 1.2469 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00203: saving model to models/bert_text_Adam_lr0.0001_bz256.203.hdf5\n",
      "Epoch 204/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.2155 - acc: 0.9398 - val_loss: 1.2516 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00204: saving model to models/bert_text_Adam_lr0.0001_bz256.204.hdf5\n",
      "Epoch 205/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.2082 - acc: 0.9484 - val_loss: 1.2591 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00205: saving model to models/bert_text_Adam_lr0.0001_bz256.205.hdf5\n",
      "Epoch 206/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.2069 - acc: 0.9413 - val_loss: 1.2607 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00206: saving model to models/bert_text_Adam_lr0.0001_bz256.206.hdf5\n",
      "Epoch 207/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.2078 - acc: 0.9474 - val_loss: 1.2576 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00207: saving model to models/bert_text_Adam_lr0.0001_bz256.207.hdf5\n",
      "Epoch 208/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.2129 - acc: 0.9413 - val_loss: 1.2661 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00208: saving model to models/bert_text_Adam_lr0.0001_bz256.208.hdf5\n",
      "Epoch 209/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.2000 - acc: 0.9496 - val_loss: 1.2670 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00209: saving model to models/bert_text_Adam_lr0.0001_bz256.209.hdf5\n",
      "Epoch 210/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2097 - acc: 0.9370 - val_loss: 1.2650 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00210: saving model to models/bert_text_Adam_lr0.0001_bz256.210.hdf5\n",
      "Epoch 211/250\n",
      "4903/4903 [==============================] - 0s 25us/step - loss: 0.2067 - acc: 0.9433 - val_loss: 1.2744 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00211: saving model to models/bert_text_Adam_lr0.0001_bz256.211.hdf5\n",
      "Epoch 212/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.1995 - acc: 0.9502 - val_loss: 1.2697 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00212: saving model to models/bert_text_Adam_lr0.0001_bz256.212.hdf5\n",
      "Epoch 213/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.2005 - acc: 0.9484 - val_loss: 1.2714 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00213: saving model to models/bert_text_Adam_lr0.0001_bz256.213.hdf5\n",
      "Epoch 214/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.1958 - acc: 0.9484 - val_loss: 1.2697 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00214: saving model to models/bert_text_Adam_lr0.0001_bz256.214.hdf5\n",
      "Epoch 215/250\n",
      "4903/4903 [==============================] - 0s 22us/step - loss: 0.2018 - acc: 0.9486 - val_loss: 1.2793 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00215: saving model to models/bert_text_Adam_lr0.0001_bz256.215.hdf5\n",
      "Epoch 216/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1984 - acc: 0.9433 - val_loss: 1.2771 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00216: saving model to models/bert_text_Adam_lr0.0001_bz256.216.hdf5\n",
      "Epoch 217/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1972 - acc: 0.9490 - val_loss: 1.2699 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00217: saving model to models/bert_text_Adam_lr0.0001_bz256.217.hdf5\n",
      "Epoch 218/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1910 - acc: 0.9460 - val_loss: 1.2868 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00218: saving model to models/bert_text_Adam_lr0.0001_bz256.218.hdf5\n",
      "Epoch 219/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.1931 - acc: 0.9462 - val_loss: 1.2875 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00219: saving model to models/bert_text_Adam_lr0.0001_bz256.219.hdf5\n",
      "Epoch 220/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.2018 - acc: 0.9425 - val_loss: 1.2737 - val_acc: 0.6656\n",
      "\n",
      "Epoch 00220: saving model to models/bert_text_Adam_lr0.0001_bz256.220.hdf5\n",
      "Epoch 221/250\n",
      "4903/4903 [==============================] - ETA: 0s - loss: 0.1966 - acc: 0.946 - 0s 33us/step - loss: 0.1958 - acc: 0.9468 - val_loss: 1.2929 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00221: saving model to models/bert_text_Adam_lr0.0001_bz256.221.hdf5\n",
      "Epoch 222/250\n",
      "4903/4903 [==============================] - 0s 33us/step - loss: 0.1947 - acc: 0.9498 - val_loss: 1.2875 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00222: saving model to models/bert_text_Adam_lr0.0001_bz256.222.hdf5\n",
      "Epoch 223/250\n",
      "4903/4903 [==============================] - 0s 20us/step - loss: 0.1913 - acc: 0.9484 - val_loss: 1.2859 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00223: saving model to models/bert_text_Adam_lr0.0001_bz256.223.hdf5\n",
      "Epoch 224/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1867 - acc: 0.9500 - val_loss: 1.2973 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00224: saving model to models/bert_text_Adam_lr0.0001_bz256.224.hdf5\n",
      "Epoch 225/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.1917 - acc: 0.9455 - val_loss: 1.2944 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00225: saving model to models/bert_text_Adam_lr0.0001_bz256.225.hdf5\n",
      "Epoch 226/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1884 - acc: 0.9498 - val_loss: 1.2982 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00226: saving model to models/bert_text_Adam_lr0.0001_bz256.226.hdf5\n",
      "Epoch 227/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1805 - acc: 0.9513 - val_loss: 1.2970 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00227: saving model to models/bert_text_Adam_lr0.0001_bz256.227.hdf5\n",
      "Epoch 228/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1839 - acc: 0.9498 - val_loss: 1.3013 - val_acc: 0.6648\n",
      "\n",
      "Epoch 00228: saving model to models/bert_text_Adam_lr0.0001_bz256.228.hdf5\n",
      "Epoch 229/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1827 - acc: 0.9494 - val_loss: 1.3032 - val_acc: 0.6623\n",
      "\n",
      "Epoch 00229: saving model to models/bert_text_Adam_lr0.0001_bz256.229.hdf5\n",
      "Epoch 230/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1808 - acc: 0.9547 - val_loss: 1.3132 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00230: saving model to models/bert_text_Adam_lr0.0001_bz256.230.hdf5\n",
      "Epoch 231/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.1894 - acc: 0.9490 - val_loss: 1.2955 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00231: saving model to models/bert_text_Adam_lr0.0001_bz256.231.hdf5\n",
      "Epoch 232/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1846 - acc: 0.9508 - val_loss: 1.3012 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00232: saving model to models/bert_text_Adam_lr0.0001_bz256.232.hdf5\n",
      "Epoch 233/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1773 - acc: 0.9541 - val_loss: 1.2996 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00233: saving model to models/bert_text_Adam_lr0.0001_bz256.233.hdf5\n",
      "Epoch 234/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.1748 - acc: 0.9543 - val_loss: 1.3091 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00234: saving model to models/bert_text_Adam_lr0.0001_bz256.234.hdf5\n",
      "Epoch 235/250\n",
      "4903/4903 [==============================] - 0s 31us/step - loss: 0.1804 - acc: 0.9535 - val_loss: 1.3091 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00235: saving model to models/bert_text_Adam_lr0.0001_bz256.235.hdf5\n",
      "Epoch 236/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1714 - acc: 0.9525 - val_loss: 1.3125 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00236: saving model to models/bert_text_Adam_lr0.0001_bz256.236.hdf5\n",
      "Epoch 237/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1770 - acc: 0.9537 - val_loss: 1.3162 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00237: saving model to models/bert_text_Adam_lr0.0001_bz256.237.hdf5\n",
      "Epoch 238/250\n",
      "4903/4903 [==============================] - 0s 27us/step - loss: 0.1685 - acc: 0.9572 - val_loss: 1.3188 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00238: saving model to models/bert_text_Adam_lr0.0001_bz256.238.hdf5\n",
      "Epoch 239/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1694 - acc: 0.9559 - val_loss: 1.3197 - val_acc: 0.6607\n",
      "\n",
      "Epoch 00239: saving model to models/bert_text_Adam_lr0.0001_bz256.239.hdf5\n",
      "Epoch 240/250\n",
      "4903/4903 [==============================] - 0s 28us/step - loss: 0.1761 - acc: 0.9521 - val_loss: 1.3198 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00240: saving model to models/bert_text_Adam_lr0.0001_bz256.240.hdf5\n",
      "Epoch 241/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.1703 - acc: 0.9519 - val_loss: 1.3219 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00241: saving model to models/bert_text_Adam_lr0.0001_bz256.241.hdf5\n",
      "Epoch 242/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.1746 - acc: 0.9527 - val_loss: 1.3232 - val_acc: 0.6591\n",
      "\n",
      "Epoch 00242: saving model to models/bert_text_Adam_lr0.0001_bz256.242.hdf5\n",
      "Epoch 243/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1700 - acc: 0.9529 - val_loss: 1.3264 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00243: saving model to models/bert_text_Adam_lr0.0001_bz256.243.hdf5\n",
      "Epoch 244/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1690 - acc: 0.9537 - val_loss: 1.3295 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00244: saving model to models/bert_text_Adam_lr0.0001_bz256.244.hdf5\n",
      "Epoch 245/250\n",
      "4903/4903 [==============================] - 0s 29us/step - loss: 0.1719 - acc: 0.9553 - val_loss: 1.3281 - val_acc: 0.6574\n",
      "\n",
      "Epoch 00245: saving model to models/bert_text_Adam_lr0.0001_bz256.245.hdf5\n",
      "Epoch 246/250\n",
      "4903/4903 [==============================] - 0s 32us/step - loss: 0.1674 - acc: 0.9535 - val_loss: 1.3310 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00246: saving model to models/bert_text_Adam_lr0.0001_bz256.246.hdf5\n",
      "Epoch 247/250\n",
      "4903/4903 [==============================] - 0s 30us/step - loss: 0.1734 - acc: 0.9549 - val_loss: 1.3307 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00247: saving model to models/bert_text_Adam_lr0.0001_bz256.247.hdf5\n",
      "Epoch 248/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1621 - acc: 0.9584 - val_loss: 1.3401 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00248: saving model to models/bert_text_Adam_lr0.0001_bz256.248.hdf5\n",
      "Epoch 249/250\n",
      "4903/4903 [==============================] - 0s 26us/step - loss: 0.1634 - acc: 0.9566 - val_loss: 1.3361 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00249: saving model to models/bert_text_Adam_lr0.0001_bz256.249.hdf5\n",
      "Epoch 250/250\n",
      "4903/4903 [==============================] - 0s 24us/step - loss: 0.1611 - acc: 0.9612 - val_loss: 1.3390 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00250: saving model to models/bert_text_Adam_lr0.0001_bz256.250.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD\n",
    "from models import load_model\n",
    "\n",
    "\n",
    "emb_size = articles_emb[0].shape[0]\n",
    "print(emb_size)\n",
    "out_size = 14\n",
    "\n",
    "model = model_MLP(emb_size, out_size)\n",
    "\n",
    "lr = 0.0001\n",
    "bz = 256\n",
    "epochs = 250\n",
    "\n",
    "opt = Adam(lr=lr)\n",
    "# opt = SGD(0.01)\n",
    "# print(str(opt))\n",
    "# exit()\n",
    "min_loss_arg = -1\n",
    "max_acc_arg = -1\n",
    "model_name = 'bert_text_Adam_lr%s_bz%s' % (lr, bz)\n",
    "model_path = 'models/%s' % (model_name)\n",
    "checkpoint = ModelCheckpoint('%s.{epoch:02d}.hdf5' % (model_path), monitor='loss', verbose=1,\n",
    "                             save_best_only=False, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "try:\n",
    "    history = model.fit(train_x, train_y, validation_data=[test_x, test_y], epochs=epochs,\n",
    "              batch_size=bz,\n",
    "              shuffle=True, callbacks=[checkpoint])\n",
    "    loss_hist = history.history['val_loss']\n",
    "    acc_hist = history.history['val_acc']\n",
    "    min_loss_arg = np.argmin(loss_hist)\n",
    "    max_acc_arg = np.argmax(acc_hist)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    min_loss_arg = -1\n",
    "    max_acc_arg = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print('max_acc_arg', max_acc_arg)\n",
    "print('min_loss_arg', min_loss_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Which epoch to load?\n",
      "Ans: 78\n",
      "Loading model -  models/bert_text_Adam_lr0.0001_bz256.78.hdf5\n"
     ]
    }
   ],
   "source": [
    "epoch = input(\"\\n\\nWhich epoch to load?\\nAns: \")\n",
    "epoch = int(epoch)\n",
    "load_model_path = '%s.%02d.hdf5' % (model_path, epoch)\n",
    "print('Loading model - ', load_model_path)\n",
    "model = load_model(load_model_path, custom_objects={'loss': 'categorical_crossentropy'})\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to file BERT_model-output-TC.txt\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(dev_articles_emb)\n",
    "predictions = predictions.argmax(axis=1)\n",
    "\n",
    "# writing predictions to file\n",
    "task_TC_output_file = \"BERT_model-output-TC.txt\"\n",
    "dev_article_ids, dev_span_starts, dev_span_ends, dev_labels = read_predictions_from_file(dev_template_labels_file)\n",
    "\n",
    "with open(task_TC_output_file, \"w\") as fout:\n",
    "    for article_id, prediction, span_start, span_end in zip(dev_article_ids, predictions, dev_span_starts,\n",
    "                                                            dev_span_ends):\n",
    "        fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, index2label[prediction], span_start, span_end))\n",
    "print(\"Predictions written to file \" + task_TC_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to file test-output-TC.txt\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_articles_emb)\n",
    "predictions = predictions.argmax(axis=1)\n",
    "\n",
    "# writing predictions to file\n",
    "test_task_TC_output_file = \"test-output-TC.txt\"\n",
    "test_article_ids, test_span_starts, test_span_ends, test_labels = read_predictions_from_file(test_template_labels_file)\n",
    "\n",
    "with open(test_task_TC_output_file, \"w\") as fout:\n",
    "    for article_id, prediction, span_start, span_end in zip(test_article_ids, predictions, test_span_starts,\n",
    "                                                            test_span_ends):\n",
    "        fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, index2label[prediction], span_start, span_end))\n",
    "print(\"Predictions written to file \" + test_task_TC_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
